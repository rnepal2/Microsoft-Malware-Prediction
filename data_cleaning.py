import os
import time
import pandas as pd

# columns to keep
keep_columns = [ 'HasDetections', 'AVProductsInstalled', 'AVProductStatesIdentifier', 'AVProductStatesIdentifier', 'AVProductStatesIdentifier',
                'Census_IsAlwaysOnAlwaysConnectedCapable', 'IsProtected', 'Census_TotalPhysicalRAM', 'Census_ProcessorCoreCount', 'Wdft_IsGamer',
                'Census_IsVirtualDevice', 'Census_PrimaryDiskTotalCapacity', 'RtpStateBitfield', 'AVProductsEnabled', 'Census_IsTouchEnabled',
                'IsSxsPassiveMode', 'Census_InternalPrimaryDiagonalDisplaySizeInInches', 'Census_InternalPrimaryDisplayResolutionHorizontal',
                'Census_OSBuildNumber', 'Census_FirmwareManufacturerIdentifier', 'OsBuild', 'Census_ProcessorModelIdentifier', 'Wdft_RegionIdentifier',
                'OsSuite', 'Census_InternalBatteryNumberOfCharges', 'Census_HasOpticalDiskDrive', 'Census_InternalBatteryType', 'Census_IsPenCapable',
                'IeVerIdentifier', 'Census_OEMNameIdentifier', 'Census_InternalPrimaryDisplayResolutionVertical', 'SMode', 'Census_SystemVolumeTotalCapacity']

# High level cleaning of data before feature engineering
# drops some columns and does NaN imputation

class DataCleaner:    
    def __init__(self):
        pass
        #self.train_df = train_df
        #self.test_df = test_df
    
    # dropping some of the unimportant/not-useful columns
    def drop_columns(self, train_df):
        # if unique categories is very large: let > 3000
        # except machine id: unique for all computers
        count = 0
        size = train_df.shape[0]
        print('Dropping some columns with unique categories > 3000......')
        print('='*20)
        for column in train_df.columns:
            if column in keep_columns: continue
            if train_df[column].nunique() != size and train_df[column].nunique() > 3000:
                del train_df[column]
                print('%s is deleted!' % column)
                count += 1
        print('columns deleted due to unique cats > 3000: ', count)

        # remove columns if has mostly one category > 0.90
        print('='*20)
        print('Dropping columns with mostly only single category')
        print('='*20)
        count = 0
        for column in train_df.columns:
            if column in keep_columns: continue
            max_cat = train_df[column].value_counts().max()/size
            if max_cat > 0.95:
                del train_df[column]
                print('%s is deleted!' % column)
                count += 1
        print('columns deleted due to single cat occupancy > 0.95: ', count)
        return train_df
    
    def columns_with_no_nan(self, train_df):
        # columns with not even a single NaN
        nonan_columns = []
        for column in train_df.columns.values:
            if train_df[column].isna().sum() == 0:
                nonan_columns.append(column)
        print('Number of without any NaN: ', len(nonan_columns))
        print('Columns without any NaN: ', nonan_columns)
    
    # resolves the nan and returns df
    def resolve_nan(self, train_df):
        # Let us look into the columns in which large amount of data are missig
        highly_nan_columns = []; nan_columns = []
        df_size = train_df.shape[0]
        for column in train_df.columns.values:
            ratio = train_df[column].isna().sum() / df_size
            if ratio > 0.3:
                highly_nan_columns.append(column)
            elif ratio > 0 and ratio <= 0.3:
                nan_columns.append(column)
            else: continue
                
        print(highly_nan_columns)
        print(nan_columns)

        # Dropping columns that have more than 30% of NaN 
        print('Dropping columns with more than 30% NaN')
        print('='*20)
        for column in highly_nan_columns:
            if column in keep_columns: continue
            del train_df[column]
            print('%s is dropped!' % column)

        # NaN imputation
        print('='*20)
        print('NaN imputation....')
        
        if not nan_columns:
            print('nano_columns list is found empty')
            return
        
        for column in nan_columns:
            # if UNKNOWN category present replace nan by UNKNOWN
            if 'UNKNOWN' in train_df[column].values:
                train_df[column].fillna('UNKNOWN', inplace=True)
                print('nan replaced by UNKNOWN category in %s.', column)
            #if dtype = float: fillna with mean
            #elif train_df[column].dtype == 'float16' or train_df[column].dtype == 'float32':
            #   mean = train_df[column].mean()
            #    train_df[column].fillna(float(mean), inplace=True)
            #   print('nan replaced by mean category in %s.', column)
            # if dtype = category, or int: fill in with the most present category
            else:
                mode = train_df[column].mode()
                train_df[column].fillna(mode, inplace=True)
                print('nan replaced by mode category in %s.', column)
        return train_df